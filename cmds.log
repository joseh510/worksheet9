    1  head -n 1 downloaded_tweets_extend_nolf.txt 
    2  cat most_retweeters.txt 
    3  frep -f most_retweeters.txt downloaded_tweets_extend_nolf.txt 
    4  fgrep -f most_retweeters.txt downloaded_tweets_extend_nolf.txt 
    5  ls
    6  cd A2
    7  ls
    8  script a2.txt
    9  ls
   10  cd A2
   11  ls
   12  script a2.txt
   13  cd /home
   14  ls
   15  cd /home/test/A1
   16  ls
   17  cp downloaded_tweets_extend_nolf2.tsv /home/jose/A2
   18  cp downloaded_tweets_extend_original_nolf2.tsv /home/jose/A2
   19  cd /home/jose/A2
   20  ls
   21  rm downloaded_tweets_extend_nolf.txt
   22  rm downloaded_tweets_extend_original_nolf.txt
   23  ls
   24  rm most_retweeters.txt 
   25  ls
   26  awk -F"\t" '($2 != $6) {print $0}' downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_NOBOT.tsv
   27  awk -F"\t" '($2 != $6) {print $0}' downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_NOBOT.tsv
   28  ls
   29  head downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
   30  cut -d\ 	-f 2  downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -n | uniq -c | sort -n | tail -50
   31  cut -f 2  downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -n | uniq -c | sort -n | tail -50
   32  cut -f 4  downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -n | uniq -c | sort -n | tail -50
   33  cut -f 6  downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -n | uniq -c | sort -n | tail -50
   34  head downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
   35  cut -f 2  downloaded_tweets_extend_nolf2_NOBOT.tsv | sort -n | uniq -c | sort -n | tail -50
   36  cut -f 4  downloaded_tweets_extend_nolf2_NOBOT.tsv | sort | uniq -c | sort -n | tail -50
   37  cut -f 4  downloaded_tweets_extend_nolf2_NOBOT.tsv | sort | uniq -c | sort -n | tail -31
   38  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv
   39  cut -f downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   40  cut -f 5 downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   41  grep "[<ReferencedTweet" downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   42  grep "type=retweeted" downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   43  grep "type=retweeted" downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 5 | head -n 10
   44  grep "type=retweeted" downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   45  grep "type=retweeted" downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 4 | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > hashtags_o
   46  ls
   47  vi hashtags_only.tsv 
   48  sort hashtags_only.tsv | uniq -c | sort | tail -50
   49  head hashtags_only.tsv 
   50  sort hashtags_only.tsv | uniq -c | sort -n | tail -50
   51  sort hashtags_only.tsv | uniq -c | sort -n | tail -31
   52  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv 
   53  cut -f 6 downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   54  cut -f 6 downloaded_tweets_extend_nolf2_NOBOT.tsv | tail -50
   55  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv 
   56  cut -f 6 downloaded_tweets_extend_nolf2_NOBOT.tsv | head -n 10
   57  sort -t "\t"  -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | tail -50 
   58  sort -t  -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | tail -50 
   59  sort -t -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | tail -50 
   60  sort -t : -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | tail -50 
   61  sort -t : -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 6 |  tail -50 
   62  sort -t : -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 6 |  head -n -50 
   63  sort -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 6 |  head -n -50 
   64  sort -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 6 |  tail -50
   65  sort -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 6 | head
   66  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv 
   67  sort -k 6,6n downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 6 | sort -n | uniq -c | sort -n| > reply_ids.tsv
   68  vi replyids.tsv
   69  rm replyids.tsv
   70  cut -f 6 downloaded_tweets_extend_nolf2_NOBOT.tsv | sort -n | uniq -c | sort -n > sorted_in_reply_to_user_id.tsv
   71  vi sorted_in_reply_to_user_id.tsv 
   72  fgrep -f sorted_in_reply_to_user_id.tsv downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 4 | sort | uniq -c | sort -n | tail -30
   73  cut -f 2 sorted_in_reply_to_user_id.tsv > only_reply_ids.tsv
   74  fgrep -f only_reply_ids.tsv  downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 4 | sort | uniq -c | sort -n | tail -30
   75  ls
   76  grep -f only_reply_ids.tsv  downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 4 | sort | uniq -c | sort -n | tail -30
   77  ls
   78  cut -f 6 downloaded_tweets_extend_nolf2_NOBOT.tsv | head -100
   79  ls
   80  fgrep -f only_reply_ids.tsv downloaded_tweets_extend_nolf2_NOBOT.tsv 
   81  vi only_reply_ids.tsv 
   82  vi sorted_in_reply_to_user_id.tsv 
   83  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv 
   84  head downloaded_tweets_extend_nolf2_NOBOT.tsv 
   85  cut -f 8 downloaded_tweets_extend_nolf2_NOBOT.tsv head -n 50
   86  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv 
   87  head downloaded_tweets_extend_nolf2_NOBOT.tsv 
   88  mkdir CUSTOMERS
   89  mkdir PRODUCTS
   90  ls
   91  head amazon_reviews_us_Books_v1_02.tsv 
   92  cut -f 2 | head -n 10
   93  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | head -n 10
   94  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /CUSTOMERS/customerID.txt
   95  ls
   96  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /ws4/CUSTOMERS/customerID.txt
   97  pwd
   98  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /home/jose/ws4/CUSTOMERS/customerID.txt
   99  ls
  100  cd CUSTOMERS/
  101  ls
  102  vi customerID.txt 
  103  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 | head -n 10
  104  pwd
  105  cd..
  106  cd ..
  107  pwd
  108  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 | head -n 10
  109  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | head -n 10
  110  head -n 1 amazon_reviews_us_Books_v1_02.tsv 
  111  egrep "12703090" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 >> /home/jose/ws4/CUSTOMERS/customerID.txt
  112  egrep "12076615" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 >> /home/jose/ws4/CUSTOMERS/customerID.txt
  113  egrep "12257412" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /home/jose/ws4/CUSTOMERS/12257412.txt
  114  egrep "12076615" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 >> /home/jose/ws4/CUSTOMERS/12076615.txt
  115  cut -4 amazon_reviews_us_Books_v1_02.tsv | head -n 10
  116  cut -f 4 amazon_reviews_us_Books_v1_02.tsv | head -n 10
  117  cut -f 4 amazon_reviews_us_Books_v1_02.tsv | head -n 6
  118  cut -f 4 amazon_reviews_us_Books_v1_02.tsv | head -n 7
  119  egrep "0316769487" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /home/jose/ws4/PRODUCTS/0316769487.txt
  120  egrep "0262181533" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /home/jose/ws4/PRODUCTS/0262181533.txt
  121  egrep "0373836635" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /home/jose/ws4/PRODUCTS/0373836635.txt
  122  ls
  123  cd CUSTOMERS/
  124  ls
  125  egrep "12703090" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 >> /home/jose/ws4/CUSTOMERS/12703090.txt
  126  cd ..
  127  egrep "12703090" amazon_reviews_us_Books_v1_02.tsv | cut -f 9 > /home/jose/ws4/CUSTOMERS/12703090.txt
  128  ls
  129  cd CUSTOMERS/
  130  ls
  131  sum=$(awk '{print $2}' file.txt | paste -sd+ | bc); echo "$sum / $(cat 12076615.txt | wc -l)" | bc -l
  132  sum=$(awk '{print $2}' 12076615.txt | paste -sd+ | bc); echo "$sum / $(cat 12076615.txt | wc -l)" | bc -l
  133  awk '{ total += $2 } END { print total/NR }' 12076615.txt
  134  ls
  135  awk '{ total += $2 } END { print total/NR }' 12257412.txt
  136  awk '{ total += $2 } END { print total/NR }' 12703090.txt
  137  vi 12703090.txt 
  138  awk '{ total += $1 } END { print total/NR }' 12076615.txt
  139  awk '{ total += $1 } END { print total/NR }' 12257412.txt
  140  awk '{ total += $1 } END { print total/NR }' 12703090.txt
  141  cd ..
  142  cd PRODUCTS/
  143  ls
  144  awk '{ total += $1 } END { print total/NR }' 0262181533.txt
  145  awk '{ total += $1 } END { print total/NR }' 0316769487.txt
  146  awk '{ total += $1 } END { print total/NR }' 0373836635.txt
  147  cd ..
  148  ls
  149  pwd
  150  history > cmds.log
  151  touch README.txt
  152  vi README.txt 
  153  ls
  154  grep "replied_to" downloaded_tweets_extend_nolf2_NOBOT.tsv | cut -f 4 | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > Q7_hashtags.tsv
  155  sort Q7_hashtags.tsv | uniq -c | sort -n | tail -31
  156  sort Q7_hashtags.tsv | uniq -c | sort -n | tail -30
  157  ls
  158  vi Q7_hashtags.tsv 
  159  sort Q7_hashtags.tsv | uniq -c | sort -n | tail -31
  160  sort Q7_hashtags.tsv | uniq -c | sort -n | tail -30
  161  ls
  162  head -n 1downloaded_tweets_extend_nolf2_NOBOT.tsv
  163  head -n 1 downloaded_tweets_extend_nolf2_NOBOT.tsv
  164  cut -f 4 downloaded_tweets_extend_nolf2_NOBOT.tsv | sort > Q8_hashtags.tsv
  165  ls
  166  vim Q8_hashtags.tsv 
  167  cut -f 4 downloaded_tweets_extend_nolf2_NOBOT.tsv | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > Q8_hashtags.tsv
  168  vim Q8_hashtags.tsv 
  169  sort Q8_hashtags.tsv | uniq -c | sort -n | tail -31
  170  sort Q8_hashtags.tsv | uniq -c | sort -n | tail -30
  171  cut -f 4 downloaded_tweets_extend_nolf2_NOBOT.tsv | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > Q8_hashtags.tsv
  172  ls
  173  cut -f 4 downloaded_tweets_extend_nolf2_NOBOT.tsv | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > Q5_hashtags.ts
  174  vi Q5_hashtags.tsv 
  175  sort Q5_hashtags.tsv | uniq -c | sort -n | tail -31
  176  ls
  177  mkdir ws4
  178  git init
  179  cd ws4
  180  git init
  181  ls
  182  cd
  183  alias l = 'ls -latr'
  184  ~/.bash_profile
  185  vi ~/.bashrc
  186  cd
  187  pwd
  188  mv amazon_reviews_us_Books_v1_02.tsv ws4
  189  ls
  190  cd ws4
  191  ls
  192  script ws4.txt
  193  git init
  194  ls
  195  git add README.txt 
  196  git add cmds.log 
  197  git add ws4.txt 
  198  git commit -m "worksheet4 files"
  199  git branch
  200  git remote add origin https://github.com/joseh510/worksheet4.git
  201  git push -u origin master
  202  ls
  203  cd ..
  204  ls
  205  cd A2
  206  script a2.txt
  207  vi a2.txt 
  208  script a2.txt
  209  vi a2.txt
  210  ls
  211  pwd
  212  git init
  213  git add a2.txt
  214  git commit -m "assignment 2"
  215  git remote add origin https://github.com/joseh510/a2.git
  216  git push -u origin master
  217  ls
  218  mkdir A3
  219  ls
  220  cd A3
  221  ls
  222  cd A3
  223  ls
  224  scrip a3.txt
  225  script a3.txt
  226  tmux new-session -s homework
  227  l
  228  ls
  229  pwd
  230  cd /home/
  231  ls
  232  cd /home/test/
  233  cd /home/jose/A2
  234  ls
  235  cp downloaded_tweets_extend_nolf2_NOBOT.tsv /home/jose/A3/
  236  cp downloaded_tweets_extend_original_nolf2_NOBOT.tsv /home/jose/A3/
  237  cd /home/jose/A3/
  238  ls
  239  script a3.txt
  240  ls
  241  head downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  242  head -n 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  243  cut -f 6 downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 150
  244  head -n 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  245  sort -k 1,1n downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 20
  246  sort -n -k 1,1n downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 20
  247  sort -k 1n downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 20
  248  sort -k 1n downloaded_tweets_extend_original_nolf2_NOBOT.tsv | cut -f 1, 6 | sort -k 1n > q1.tsv
  249  sort -k 1n downloaded_tweets_extend_original_nolf2_NOBOT.tsv | cut -f 1,6 | sort -k 1n > q1.tsv
  250  ls
  251  vi q1.tsv
  252  ls
  253  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 1n | cut -f 1,6 > question1.tsv
  254  ls
  255  vi question1.tsv 
  256  ls
  257  cd A2
  258  cd /home/jose/A3
  259  ls
  260  tmux attach -t homework
  261  ls
  262  cd A3
  263  ls
  264  script a3.txt
  265  ls
  266  pwd
  267  cd A3
  268  ls
  269  tmux attach -t homework
  270  ls
  271  cd A3
  272  tmux attach -t homework
  273  awk -F, 'FNR == NR { count[$2]++ }
  274  cp question1.csv backup_question1.csv
  275  ls
  276  awk -F, 'FNR == NR { count[$1]++ } FNR != NR { if (count[$1] >= 3) print }' question1.csv question1.csv
  277  awk -F, 'FNR == NR { count[$1]++ } FNR != NR { if (count[$1] >= 3) print }' question1.csv question1.csv > question2.csv
  278  vi question2.csv
  279  ls
  280  mv sorted_6_2.csv question1.csv
  281  ls
  282  vi question1.csv
  283  awk '++a[$3]==3{ print $3 }' file
  284  awk '++a[$1]==3{ print $1 }' question1.csv > question2.csv
  285  vi question2.csv
  286  sort -k 1n question1.csv | cut -f 1 | uniq -c | sort -n
  287  sort -k 1n question1.csv | cut -f 1 | uniq -c | sort -n | tail -50
  288  cut -f 1 question1.csv | uniq -c | sort -n | tail -50
  289  cut -d \, -f 1 question1.csv | uniq -c | sort -n | tail -50
  290  cut -d \, -f 1 question1.csv | sort -n | uniq -c | sort -n | tail -50
  291  cut -d \, -f 1 question1.csv | sort -n | uniq -c | sort -n | tail -100
  292  cut -d \, -f 1 question1.csv | sort -n | uniq -c | sort -n | tail -200
  293  sort -t , -k 1n question1.csv > question1.csv
  294  vi question1.csv
  295  vi sorted_6_2.csv
  296  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{print $6 "," $2}' > grepped_field_6_2.csv
  297  sort -t , -k 1,1n grepped_field_6_2.csv > question1.csv
  298  vi question1.csv
  299  awk -F "," 'NR==FNR{a[$1]++; next} a[1]>=3' question1.csv question1.csv > question2.csv
  300  vi question2.csv
  301  awk -F "," 'NR==FNR{a[$1]++; next} a[1]==3' question1.csv question2.csv
  302  vi question2.csv 
  303  awk -F "," 'NR==FNR{a[$1]++; next} a[1]==3' question1.csv question1.csv
  304  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{print $6 "," $2}' > grepped_field_6_2.csv
  305  sort -t , -k 1,1n grepped_field_6_2.csv > question1.csv
  306  $ awk -F "," 'NR==FNR{a[$1]++; next} a[$1]>=3' question1.csv > question2.csv
  307  $ awk 'NR==FNR{a[$1]++; next} a[$1]>=3' question1.csv > question2.cs/;q`
  308  ls
  309  awk '{print $1}' question1.csv | uniq -c | sort -t , -k 1n | awk '{ if ($1 >= 3) {print} }' > question2.csv
  310  vi question2.csv 
  311  awk '{ if ($1 >= 3) {print} }' > question2.csv
  312  awk '{ if ($1 >= 3) {print} }' question1.csv  > question2.csv
  313  vi question2.csv
  314  scrip a3.txt
  315  script a3.txt
  316  ls
  317  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 6n | awk '{ print $6 " " $2}' > q1.tsv
  318  vi q1.tsv 
  319  head -n 1 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  320  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 6n | awk '{ print $6 "," $2}' > q1.tsv
  321  vi q1.tsv
  322  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk '{ print $6 "," $2}' > q1.tsv
  323  vi q1.tsv
  324  ls
  325  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk '{ print $6 "\t" $2}' > q1.tsv
  326  vi q1.tsv
  327  head downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  328  head -n 50 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  329  head -n 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  330  cut -f 6 downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 10
  331  awk '{ print $6 "\t" $2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv > q1.tsv
  332  vi q1.tsv
  333  awk '{ print $6 "\t" $2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv > q1.tsv
  334  vi q1.tsv
  335  awk -F "\t" '{ print $6 "," $2 }' downloaded_tweets_extend_original_nolf2_NOBOT.tsv > q1.tsv
  336  vi q1.tsv
  337  awk -F "\t" '{ print $6 "\t" $2 }' downloaded_tweets_extend_original_nolf2_NOBOT.tsv > q1.tsv
  338  q1.tsv
  339  vi q1.tsv
  340  awk -F "\t" '{ print $6 "\t" $2 }' downloaded_tweets_extend_original_nolf2_NOBOT.tsv > q1.tsv
  341  vi q1.tsv
  342  awk -F "\t" '{ print $6 }' downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 100
  343  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk '{ print $6 }' | head -n 100
  344  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk '{ print $7 }' | head -n 100
  345  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{ print $6 } | head -n 100
  346  awk -F "\t" '{ print $6 }'  downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 100
  347  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{ print $6 }' | head -n 100
  348  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{ print $6 "," print $2 }' | head -n 100
  349  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{ print $6 "," $2 }' | head -n 100
  350  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{ print $6 "\t" $2 }' | head -n 100
  351  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{ print $6 "," $2 }' > grepped_field_6_2.csv
  352  sort -k 1n grepped_field_6_2.csv > sorted_6_2.csv
  353  vi sorted_6_2.csv 
  354  ls
  355  script a3.txt
  356  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 1n | cut -f 1,6 > question1.tsv
  357  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 1n | cut -f 1,6 | uniq -c | sort -k 1n | tail -20
  358  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 1n | cut -f 1,6 | sort -k 1n | tail -20
  359  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 1n | cut -f 1 | sort -n | uniq -c | tail -20
  360  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 1n | cut -f 1 | sort -n | uniq -c |sort -n| tail -20
  361  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | cut -f 1 | sort -n | uniq -c |sort -n| tail -20
  362  cut -f 1 | sort -n downloaded_tweets_extend_original_nolf2_NOBOT.tsv | uniq -c |sort -n| tail -20
  363  cut -f 1 downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -n | uniq -c |sort -n| tail -20
  364  head -n 1 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  365  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 2n | cut -f 2,6 > question1.tsv
  366  vi question1.tsv 
  367  cut -f 2 question1.tsv | sort -n | uniq -c | sort -n |tail -50 
  368  cut -f 2 question1.tsv | sort -n | uniq -c | sort -n | tail -100 
  369  cut -f 2 question1.tsv | sort -n | uniq -c | sort -n | tail -200 
  370  ls
  371  grep "1031000589054828544" question1.tsv 
  372  grep "1031000589054828544" question1.tsv | wc 
  373  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 2n | cut -f 6,2 > question2.tsv
  374  ls
  375  vi question2.tsv 
  376  grep "1031000589054828544" question2.tsv
  377  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 2n | cut -f 6 > question2.tsv
  378  grep "replied_to" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 2n | cut -f 2 >> question2.tsv
  379  grep "1031000589054828544" question2.tsv
  380  grep "1031000589054828544" question1.tsv | wc -l 
  381  awk '/\<1031000589054828544\>/{print NR}' question1.tsv
  382  l
  383  ls
  384  sort -k 2n question1.tsv ls| uniq -c | gawk '$1>=3{print $2}' 
  385  ls
  386  cat downloaded_tweets_extend_original_nolf2_NOBOT.tsv | sort -k 6n | cut -f 6,2 > correct_question2.tsv
  387  vi correct_question2.tsv 
  388  cat downloaded_tweets_extend_original_nolf2_NOBOT.tsv | grep "replied_to"  | sort -k 6n | cut -f 6,2 > correct_question2.tsv
  389  vi correct_question2.tsv 
  390  cat downloaded_tweets_extend_original_nolf2_NOBOT.tsv | grep "replied_to"  | sort -k 6n | cut -f 2,6 | sort -k 2n > correct_question2.tsv
  391  vi correct_question2.tsv 
  392  grep "1031000589054828544" correct_question2.tsv 
  393  grep "1031000589054828544" correct_question2.tsv | wc -l
  394  awk '/\<1031000589054828544\>/{print NR}' correct_question2.tsv 
  395  vi correct_question2.tsv 
  396  ls
  397  awk '++a[$2]>=3{ print $2 }' correct_question2.tsv > question2_3_or_more.tsv
  398  ls
  399  vi question2_3_or_more.tsv 
  400  ls
  401  rm correct_question2.tsv 
  402  rm question1.tsv 
  403  rm question2.tsv 
  404  rm question2_3_or_more.tsv 
  405  ls
  406  pwd
  407  script a3.txt
  408  ls
  409  script a3.txt
  410  ls
  411  cd A3
  412  tmux attach -t homework
  413  ls
  414  gnuplot
  415  ls
  416  cd A3
  417  ls
  418  tmux attach -t homework
  419  gnuplot
  420  echo $DISPLAY
  421  gnuplot
  422  systemctl enable --now cockpit.socket
  423  /etc/gnuplot-5.4.4/src/gnuplot
  424  ls
  425  /etc/gnuplot-5.4.4/src/gnuplot
  426  display question2.csv.svg
  427  display question2.svg
  428  cd src
  429  /etc/gnuplot-5.4.4/src/gnuplot
  430  ls
  431  cd A3
  432  ls
  433  script a3.txt
  434  ls
  435  pwd
  436  cd gnuplot-5.4.5/src/
  437  cd /home
  438  ls
  439  cd gnuplot-5.4.5/src/
  440  display question3.svg
  441  display gnuplot-5.4.4/src/1.svg
  442   cd gnuplot-5.4.4/src/1.svg
  443   cd gnuplot-5.4.4/src/
  444  cd
  445  pwd
  446  cd ..
  447  ls
  448  ls -a
  449   cd gnuplot-5.4.5/src/
  450   /etc/gnuplot-5.4.4/src/gnuplot
  451  ls -latr
  452  display filename.svg
  453   /etc/gnuplot-5.4.4/src/gnuplot
  454  ls
  455  cd A3
  456   /etc/gnuplot-5.4.4/src/gnuplot
  457  ls -latr
  458  display question3.svg
  459  script a3.txt
  460  ls -latr
  461  display q3plot.svg
  462  l
  463  ls
  464  cd A3
  465  ls
  466  cut -d \, -f 1 question1.csv | sort -n | uniq -c | sort -n | tail -100
  467  cut -d \, -f 1 question1.csv | sort -n | uniq -c | sort -n 
  468  cut -d \, -f 1 question1.csv | sort -n | uniq -c | sort -n > for_q3_plot.txt
  469  ls
  470   /etc/gnuplot-5.4.4/src/gnuplot
  471  ls -latr
  472   /etc/gnuplot-5.4.4/src/gnuplot
  473  ls -latr
  474  display correctq3plot.svg 
  475  systemctl enable --now cockpit.socket
  476  l
  477  ls -latr
  478  ls
  479  cd A3
  480  ls
  481  display q3plot.svg
  482  cd ...
  483  cd ..
  484  pwd
  485  ls
  486  display filname.svg
  487  gnuplot
  488   /etc/gnuplot-5.4.4/src/gnuplot
  489  ls -latr
  490  display 2correctq3plot.svg 
  491  ls -latr
  492  display 2correctq3plot.svg 
  493  ls
  494  cd A3
  495  ls -latr
  496  display question3.svg
  497  ls
  498  display filename.svg 
  499  ls
  500  cd A3
  501  ls
  502  ls
  503  script a3.txt
  504  display gnuplot
  505  display gnuplot-5.4.4/src/ws5/svg
  506  gnuplot
  507   /etc/gnuplot-5.4.4/src/gnuplot
  508  ls -latr
  509  display 2correctq3plot.svg
  510  ls -latr
  511  display 2correctq3plot.svg 
  512  ls
  513  cd A3
  514  ls
  515  cd A3
  516  pwd
  517  ls
  518  script a3.txt
  519  ls
  520  cd A3
  521  ls
  522  script a3.txt
  523  pwd
  524  cd ..
  525  pwd
  526  mkdir ws5
  527  cd ws5
  528  ls
  529  pwd
  530  git init
  531  script ws5.txt
  532  ls
  533  tmux new-session -s homework
  534  ls
  535  cd ws5
  536  ls
  537  script ws5.txt
  538  ls
  539  head -n 1 amazon_reviews_us_Books_v1_02.tsv 
  540  ls
  541  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c | sort -n | cut -d \  -f 2 | tail -1000
  542  ls
  543  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c | sort -n | tail -1000
  544  tmux attach -t homework
  545  ls
  546  cd ..
  547  ls
  548  pwd
  549  cd A1
  550  ls
  551  cd ..
  552  cd A2
  553  ls
  554  pwd
  555  cd ..
  556  pwd
  557  ls
  558  cd ws5
  559  cd ..
  560  cd ws4
  561  ls
  562  mv amazon_reviews_us_Books_v1_02.tsv ws5
  563  cd ..
  564  cd ws5
  565  ls
  566  mv amazon_reviews_us_Books_v1_02.tsv /home/jose/ws5
  567  cd /home/jose/ws2
  568  cd /home/jose/ws4
  569  mv amazon_reviews_us_Books_v1_02.tsv /home/jose/ws5
  570  ls
  571  ls -latr
  572  pwd
  573  cd ..
  574  ls
  575  cd ws4
  576  ls
  577  rm ws5
  578  ls
  579  ls -latr
  580  cd ..
  581  pwd
  582  ls
  583  cd ws5
  584  ls
  585  ls -latr
  586  cd ..
  587  ls -latr
  588  ls -R
  589  ls
  590  cd ws5
  591  ls
  592  wget    https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz
  593  gzip -d amazon_reviews_us_Books_v1_02.tsv.gz 
  594  ls
  595  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c| sort -n | tail -1000 > top1000_cust_ids.txt
  596  vi top1000_cust_ids.txt 
  597  fgrep -f top1000_cust_ids.txt amazon_reviews_us_Books_v1_02.tsv | sort -k 2n > top_1000_cust_id_lines.tsv
  598  vi top_1000_cust_id_lines.tsv 
  599  mv top1000_cust_ids.txt top1000_cust_ids.tsv
  600  ls
  601  fgrep -f top1000_cust_ids.tsv amazon_reviews_us_Books_v1_02.tsv | sort -k 2n > top_1000_cust_id_lines.tsv
  602  vi top_1000_cust_id_lines.tsv 
  603  ls
  604  rm top1000_cust_ids.tsv 
  605  ls
  606  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c| sort -n | tail -1000 > top1000_cust_ids.txt
  607  cut -d /" " -f 2 top1000_cust_ids.txt > customer_IDs.tsv
  608  cut -f 2 top1000_cust_ids.txt > customer_IDs.tsv
  609  vi customer_IDs.tsv 
  610  vi top1000_cust_ids.txt 
  611  rm customer_IDs.tsv 
  612  ls
  613  rm top_1000_cust_id_lines.tsv 
  614  ls
  615  grep -f top1000_cust_ids.txt amazon_reviews_us_Books_v1_02.tsv | sort -k 2n > top_1000_cust_id_lines.tsv
  616  vi top_1000_cust_id_lines.tsv 
  617  mv top1000_cust_ids.txt top1000_cust_ids.tsv
  618  grep -f top1000_cust_ids.tsv amazon_reviews_us_Books_v1_02.tsv | sort -k 2n > top_1000_cust_id_lines.tsv
  619  ls
  620  vi top_1000_cust_id_lines.tsv 
  621  grep -f top1000_cust_ids.txt amazon_reviews_us_Books_v1_02.tsv > top_1000_cust_id_lines.tsv
  622  ls
  623  vi top1000_cust_ids.tsv 
  624  rm top1000_cust_ids.tsv 
  625  ls
  626  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c| sort -n | tail -1000 > top1000_cust_ids.txt
  627  vi top1000_cust_ids.txt 
  628  vi top1000_cust_ids.txt
  629  ls
  630  grep -f top1000_cust_ids.txt amazon_reviews_us_Books_v1_02.tsv > top_1000_cust_id_lines.tsv
  631  vi top_1000_cust_id_lines.tsv 
  632  grep -f top1000_cust_ids.txt amazon_reviews_us_Books_v1_02.tsv | tail -250
  633  awk '{$1="";print}' top1000_cust_ids.txt  | tail -100
  634  awk '{$1="";print}' top1000_cust_ids.txt  > only_customer_ids_top1000.txt
  635  grep -f only_customer_ids_top1000.txt amazon_reviews_us_Books_v1_02.tsv | tail -250
  636  vi only_customer_ids_top1000.txt 
  637  grep -F -x -f only_customer_ids_top1000.txt amazon_reviews_us_Books_v1_02.tsv | tail -250
  638  grep -e -x -f only_customer_ids_top1000.txt amazon_reviews_us_Books_v1_02.tsv | tail -250
  639  grep -e -f only_customer_ids_top1000.txt amazon_reviews_us_Books_v1_02.tsv | tail -250
  640  grep -e -f only_customer_ids_top1000.txt amazon_reviews_us_Books_v1_02.tsv | sort -k 2n > top1000_reviews.txt
  641  vi top1000_reviews.txt 
  642  wc -l top1000_reviews.txt 
  643  for i in {0..133017};
  644  mkdir CUSTOMERS
  645  ls
  646  for i in {0..133017};
  647  ls
  648  ls
  649  cd ws5
  650  ls
  651  script ws5.txt
  652  ls
  653  tmux attach -t homework
  654  head -n top1000_cust_ids.txt 
  655  head -n 1 top1000_cust_ids.txt 
  656  head -n 1 top1000_reviews.txt 
  657  head -n 1 amazon_reviews_us_Books_v1_02.tsv 
  658  $ awk -F, '{print >> /CUSTOMERS/$2".txt"}' top1000_reviews.txt
  659  $ awk -F"\t" '{print >> /CUSTOMERS/$2".txt"}' top_1000_cust_id_lines.tsv 
  660  awk -F"\t" '{print >> /CUSTOMERS/$2".txt"}' top_1000_cust_id_lines.tsv
  661  ls
  662  cd CUSTOMERS/
  663  ls
  664  cd ..
  665  head top_1000_cust_id_lines.tsv 
  666  vi top_1000_cust_id_lines.tsv 
  667  vi top1000_reviews.txt 
  668  awk -F"\t" '{print >> /CUSTOMERS/$2".txt"}' top1000_reviews.txt
  669  ls
  670  vi 025298967.txt
  671  mv 0* /home/jose/ws5/CUSTOMERS
  672  ls
  673  mv 1* /home/jose/ws5/CUSTOMERS
  674  ls
  675  history > cmds.log
  676  ls
  677  ls
  678  cd ws5
  679  ls
  680  tmux attach -t homework
  681  script ws5.txt
  682  vi ws5.txt
  683  ls
  684  vi ws5.txt
  685  ls
  686  git add ws5.txt 
  687  git add cmds.log 
  688  git init
  689  git status
  690  git commit -m  "workseet5 files"
  691  git remote add origin https://github.com/joseh510/worksheet5.git
  692  git push -u origin master
  693  ls -latr
  694  pwd
  695  cd ..
  696  ls
  697  pwd
  698  ls
  699  cd ws5
  700  ls
  701  tail -100 top1000_cust_ids.txt 
  702  cd ..
  703  ls
  704  cd a3
  705  cd A3
  706  ls
  707  tmux attach -t homework
  708  tmux new-session -s homework
  709  head -n 1 tweeted_clusters.tsv
  710  ls
  711  cut -d \, -f 1 question2.csv > field6_only_largest_clusters.csv
  712  ls
  713  grep -e -f field6_only_largest_clusters.csv downloaded_tweets_extend_original_nolf2_NOBOT.tsv | cut -f 4 | tr '[:upper:
  714  grep -e -f field6_only_largest_clusters.csv downloaded_tweets_extend_original_nolf2_NOBOT.tsv | cut -f 4 | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > largest_cluster_hashtags.tsv
  715  vi largest_cluster_hashtags.tsv 
  716  sort -n largest_cluster_hashtags.tsv | uniq -c | sort -n | tail -50
  717  sort -n largest_cluster_hashtags.tsv | uniq -c | sort -n | tail -30 > 30_most_freq_hasthags_in_largest_clusters.tsv
  718  touch 30_most_frequent_hashtags_q5.tsv
  719  ls
  720  vi 30_most_frequent_hashtags_q5.tsv 
  721  diff 30_most_freq_hasthags_in_largest_clusters.tsv 30_most_frequent_hashtags_q5.tsv 
  722  diff -y 30_most_freq_hasthags_in_largest_clusters.tsv 30_most_frequent_hashtags_q5.tsv 
  723  diff -X 30_most_freq_hasthags_in_largest_clusters.tsv 30_most_frequent_hashtags_q5.tsv 
  724  diff -x 30_most_freq_hasthags_in_largest_clusters.tsv 30_most_frequent_hashtags_q5.tsv
  725  sort 30_most_freq_hasthags_in_largest_clusters.tsv | tail -30
  726  awk '{$1="";print}' 30_most_freq_hasthags_in_largest_clusters.tsv  > only_30_most_freq_hasthags_in_largest_clusters.tsv
  727  awk '{$1="";print}' 30_most_frequent_hashtags_q5.tsv  > only_30_most_frequent_hashtags_q5.tsv
  728  sort only_30_most_freq_hasthags_in_largest_clusters.tsv > only_30_most_freq_hasthags_in_largest_clusters.tsv
  729  sort only_30_most_frequent_hashtags_q5.tsv > only_30_most_frequent_hashtags_q5.tsv
  730  diff -y only_30_most_freq_hasthags_in_largest_clusters.tsv only_30_most_frequent_hashtags_q5.tsv
  731  cat only_30_most_freq_hasthags_in_largest_clusters.tsv
  732  vi only_30_most_freq_hasthags_in_largest_clusters.tsv
  733  awk '{$1="";print}' 30_most_frequent_hashtags_q5.tsv | sort | tail -50
  734  awk '{$1="";print}' 30_most_frequent_hashtags_q5.tsv | sort > only_30_most_freq_hasthags_in_largest_clusters.tsv
  735  awk '{$1="";print}' 30_most_frequent_hashtags_q5.tsv | sort | tail -30
  736  awk '{$1="";print}' 30_most_frequent_hashtags_q5.tsv | sort > only_30_most_freq_hasthags_in_largest_clusters.tsv
  737  awk '{$1="";print}' 30_most_freq_hasthags_in_largest_clusters.tsv | sort > only_30_most_freq_hasthags_in_largest_clusters.tsv
  738  diff -y only_30_most_freq_hasthags_in_largest_clusters.tsv only_30_most_frequent_hashtags_q5.tsv
  739  diff only_30_most_freq_hasthags_in_largest_clusters.tsv only_30_most_frequent_hashtags_q5.tsv
  740  diff -y 30_most_freq_hasthags_in_largest_clusters.tsv 30_most_frequent_hashtags_q5.tsv 
  741  diff -y only_30_most_freq_hasthags_in_largest_clusters.tsv only_30_most_frequent_hashtags_q5.tsv
  742  diff -x only_30_most_freq_hasthags_in_largest_clusters.tsv only_30_most_frequent_hashtags_q5.tsv
  743  vi only_30_most_frequent_hashtags_q5.tsv 
  744  ls
  745  vi question1.csv 
  746  cd ..
  747  ls
  748  mv 2correctq3plot.svg /home/jose/A3
  749  ls
  750  cd A3
  751  ls
  752  ls
  753  cd A3
  754  ls
  755  script A3.txt
  756  head question2.csv
  757  cut -d /, -f 1 question2.csv > largest_clusters_only.csv
  758  cut -d/, -f 1 question2.csv > largest_clusters_only.csv
  759  cut -d \, -f 1 question2.csv > largest_clusters_only.csv
  760  ls
  761  grep -f -e largest_clusters_only.csv downloaded_tweets_extend_original_nolf2_NOBOT.tsv > tweet_clusters.tsv
  762  ls
  763  grep -e -f  largest_clusters_only.csv downloaded_tweets_extend_original_nolf2_NOBOT.tsv > tweeted_clusters.tsv
  764  ls
  765  head -n 1 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  766  cut -d \, -f 4 tweeted_clusters.tsv | tr '[:upper:]' '[:lower:]' | tr ',' '\n' > largest_cluster_hashtags.tsv
  767  vi largest_cluster_hashtags.tsv 
  768  tmux attach -t homework
  769  ls
  770  cd A2
  771  ls
  772  cd ..
  773  ls
  774  cd A2
  775  pwd
  776  ls
  777  cd ..
  778  pwd
  779  ls -R
  780  ls
  781  pwd
  782  ls
  783  cd A2
  784  ls
  785  cd ..
  786  cd ws4
  787  ls
  788  cd PRODUCTS/
  789  ls
  790  vi 0316769487.txt 
  791  pwd
  792  cd ..
  793  ls
  794  cd A2
  795  ls
  796  cd ..
  797  cd A3
  798  ls
  799  cd ..
  800  ls
  801  mkdir ws6
  802  ls
  803  cd ws6
  804  pwd
  805  cd ..
  806  ls
  807  cd ws5
  808  ls
  809  mv amazon_reviews_us_Books_v1_02.tsv /home/jose/ws6
  810  ls
  811  pwd
  812  ls
  813  cd ..
  814  cd ws6
  815  ls
  816  tmux new-session -s homework
  817  tmux attach -t homework'
  818  tmux attach -t homework
  819  ls
  820  cd ws6
  821  tmux attach -t homework
  822  ls
  823  cd
  824  df -H
  825  ls
  826  pwd
  827  cd ..
  828  lw
  829  ls
  830  ls -latr
  831  ls
  832  cd /mnt/scratch/
  833  ls
  834  cd jose
  835  ls
  836  pwd
  837  cp /home/jose/ws6 /mnt/scratch/jose
  838  cp -r /home/jose/ws6 /mnt/scratch/jose
  839  ls
  840  cd ws6
  841  ls
  842  vi cronshell.sh
  843  ls
  844   ls
  845  cd /home/jose
  846  ls
  847  vi cronshell.sh
  848  cd ws6
  849  ls
  850  cd PRODUCTS/
  851  ls
  852  pwd
  853  cd /home/jose
  854  ls
  855  cd /mnt/scratch/jose/
  856  ls
  857  cd ws6
  858  tmux attach -t homework
  859  ls
  860  jose
  861  cd /mnt/scratch/jose/
  862  ls
  863  ws6
  864  cd ws6
  865  ls
  866  script ws6.txt
  867  export DATETIME=`date "+%Y%m%d_%H%M%S"`
  868  OUTDIR=out.$DATETIME
  869  echo "Using $DATETIME for outdir suffix"
  870  cp lines0385504209.DATETIME.txt onlylines0385504209.$DATETIME.txt
  871  cd PRODUCTS/
  872  cp lines0385504209.DATETIME.txt onlylines0385504209.$DATETIME.txt
  873  ls
  874  rep -e "RQ58W7SMO911M" amazon_reviews_us_Books_v1_02.tsv >> /home/jose/ws6/PRODUCTS/onlylines0385504209.20221019_035822.txt
  875  grep -e "RQ58W7SMO911M" amazon_reviews_us_Books_v1_02.tsv >> /home/jose/ws6/PRODUCTS/onlylines0385504209.20221019_035822.txt
  876  pwd
  877  grep -e "RQ58W7SMO911M" /mnt/scratch/jose/ws6/amazon_reviews_us_Books_v1_02.tsv >> /home/jose/ws6/PRODUCTS/onlylines0385504209.20221019_035822.txt
  878  grep -e "RQ58W7SMO911M" /mnt/scratch/jose/ws6/amazon_reviews_us_Books_v1_02.tsv >> /mnt/scratch/jose/ws6/PRODUCTS/onlylines0385504209.20221019_035822.txt
  879  tail -1 onlylines0385504209.20221019_035822.txt
  880  ln -s onlylines0385504209.20221019_035822.txt symlinkonlylines0385504209.20221019_035822.txt
  881  ls
  882  tmux attach -t homework
  883  l
  884  ls
  885  tmux attach -t homework
  886  ls
  887  tmux attach -t homework
  888  ls
  889  tmux attach -t homework
  890  cut -f 14 onlylines0385504209_fav_product.txt | sed 's/[,.;]//g' > fav_prod_review_column.txt
  891  sed -i 's/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/s//g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  892   sed -i 's/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/ s //g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  893   sed -i 's/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/ \s //g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  894   sed -i "s/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/ s //g;s/br//g" fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  895   sed -i "s/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/ \s //g;s/br//g" fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  896   sed -i "s/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/\ s //g;s/br//g" fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  897   sed -i "s/and//g;s/or//g;s/if//g;s/in/g;s/it//g;s/br//g" fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  898   sed -i 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  899   sed -i 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g;s/ s//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  900  sed 's|[</>]||g' fav_prod_review_column_part2.txt > fav_prod_review_column_part3.txt
  901  vi fav_prod_review_column_part3.txt 
  902  vi fav_prod_review_column_part2.txt 
  903  vi fav_prod_review_column.txt 
  904   sed -i 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g;s/ s//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  905  vi fav_prod_review_column_part2.txt
  906   sed -i 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g;s/ s / /g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  907  vi fav_prod_review_column_part2.txt 
  908   sed -i 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  909  vi fav_prod_review_column_part2.txt 
  910  sed -i 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  911  vi fav_prod_review_column_part2.txt 
  912  sed 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  913  vi fav_prod_review_column_part2.txt 
  914  sed 's|[</>]||g' fav_prod_review_column_part2.txt > fav_prod_review_column_part3.txt 
  915  vi fav_prod_review_column_part3.txt 
  916  vi ws7.txt 
  917  pwd
  918  git init
  919  ls
  920  history > cmds.log
  921  ls
  922  pwd
  923  tmux attach -t homework
  924  ls
  925  tmux attach -t homework
  926  awk -Fa “\t” {print $12} amazon_reviews_us_Books_v1_02.tsv | grep Y > 
  927  head -n 1 amazon_reviews_us_Books_v1_02.tsv 
  928  awk -F “\t” {print $12} amazon_reviews_us_Books_v1_02.tsv | grep 'Y' > verified.txt
  929  awk -F "\t" {print $12} amazon_reviews_us_Books_v1_02.tsv | grep 'Y' > verified.txt
  930  awk -F "\t" '($12=="Y")'  amazon_reviews_us_Books_v1_02.tsv  > verified.txt
  931  vi verified.txt 
  932  awk -F "\t" '($12=="N")'  amazon_reviews_us_Books_v1_02.tsv  > unverified.txt
  933  cut -f 14 verified.txt | sed 's/[,.;]//g' > verified_pt1.txt
  934  cut -f 14 unverified.txt | sed 's/[,.;]//g' > unverified_pt1.txt
  935  sed 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' fav_prod_review_column.txt > fav_prod_review_column_part2.txt
  936  sed 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' verified_pt1.txt > verified_pt2.txt
  937  sed 's/and//g;s/or//g;s/if//g;s/in//g;s/it//g;s/br//g' unverified_pt1.txt > unverified_pt2.txt
  938  sed 's|[</>]||g' verified_pt2.txt > verified_pt3.txt
  939  sed 's|[</>]||g' unverified_pt2.txt > unverified_pt3.txt
  940  vi verified_pt3.txt 
  941  tr
  942  tr 
  943  tr '[:upper:]' '[:lower:]' verified_pt3.txt | tr ' ' '\n' | sort | uniq -c | sort| tail -50 
  944  cat verified_pt3.txt | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | sort | uniq -c | sort | tail -50 
  945  cat verified_pt3.txt | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | sort | uniq -c | sort | tail -20 > 10_most_freq_words_verified.txt 
  946  vi 10_most_freq_words_verified.txt 
  947  cat unverified_pt3.txt | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | sort | uniq -c | sort | tail -20 > 10_most_freq_words_unverified.txt
  948  vi unverified_pt3.txt
  949  cat unverified_pt3.txt | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | sort | uniq -c | sort | tail -20 > 10_most_freq_words_unverified.txt
  950  vi 10_most_freq_words_unverified.txt 
  951  cat verified_pt3.txt | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | sort | uniq -c | sort -n | tail -20 > 10_most_freq_words_verified.txt
  952  vi 10_most_freq_words_verified.txt 
  953  cat unverified_pt3.txt | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | sort | uniq -c | sort -n | tail -20 > 10_most_freq_words_unverified.txt
  954  vi 10_most_freq_words_unverified.txt 
  955  history > cmds.log
  956  ls
  957  git init
  958  vi ws8.txt
  959  ls
  960  ls
  961  cd A3
  962  ls
  963  cp downloaded_tweets_extend_nolf2_NOBOT.tsv /mnt/scratch/jose
  964  cp downloaded_tweets_extend_original_nolf2_NOBOT.tsv /mnt/scratch/jose
  965  cd /mnt/scratch/jose
  966  ls
  967  mv downloaded_tweets_extend_nolf2_NOBOT.tsv /mnt/scratch/jose/a4
  968  mv downloaded_tweets_extend_original_nolf2_NOBOT.tsv /mnt/scratch/jose/a4
  969  ls
  970  cd a4
  971  ls
  972  tmux attach -t homework
  973  ls
  974  vi retweet
  975  rm retweet
  976  ls
  977  head -n 1 downloaded_tweets_extend_original_nolf2_NOBOT.tsv 
  978  grep "retweeted" downloaded_tweets_extend_nolf2_NOBOT.tsv | awk -F '\t' '{print $5}' | sed 's/^.* id=//g' | sed 's/type=retweeted.//g' > retweeted_ids.tsv
  979  fgrep -f retweeted_ids.tsv | awk -F '\t' '{print $2} > users_retweeted.tsv
  980  fgrep -f retweeted_ids.tsv | awk -F '\t' '{print $2}' > users_retweeted.tsv
  981  fgrep -f retweeted_ids.tsv downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F '\t' '{print $2}' > users_retweeted.tsv
  982  sort users_retweeted.tsv | uniq -c | sort -n > sorted_users_retweeted.tsv
  983  awk -F, 'FNR==NR {count[$1]++} FNR != NR {if (count[$1] >=3) print}' users_retweeted.tsv users_retweeted.tsv > users_3_or_more_retweets.tsv
  984  vi users_3_or_more_retweets.tsv 
  985  vi sorted_users_retweeted.tsv 
  986  tail -10 sorted_users_retweeted.tsv 
  987  ls
  988  git init
  989  ls
  990  pwd
  991  cd /mnt/scratch/jose
  992  ls
  993  mkdir ws9
  994  ls
  995  cd ws9
  996  ls
  997  script ws9.txt
  998  vi randomsample.sh 
  999  vi ws9.txt
 1000  history > cmds.log
